{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "-----\n",
      "x:  [0.49371378 0.63800579 0.77470965 0.64438818 0.19670207 0.07308795\n",
      " 0.06979703 0.30618327 0.66376063 0.66920123]\n",
      "x_t_beta :  [1.30720702]\n",
      "w :  0.07222462960787528\n",
      "y :  1.3794316541583609\n",
      "[0.        ,1.37943165,0.49371378,0.63800579,0.77470965,0.64438818,\n",
      " 0.19670207,0.07308795,0.06979703,0.30618327,0.66376063,0.66920123]\n"
     ]
    }
   ],
   "source": [
    "n=10   # number of inputs\n",
    "\n",
    "beta=np.zeros(n) ## first and last parameters are 1, others are zeros\n",
    "beta[1]=1   \n",
    "beta[-1]=1\n",
    "print(beta)\n",
    "beta.shape=(n,1)\n",
    "print(beta)\n",
    "print(\"-----\")\n",
    "x=np.random.rand(1,n)[0]\n",
    "print(\"x: \", x)\n",
    "x_T_beta = x.dot(beta)\n",
    "w = 0.1*np.random.rand(1)[0]\n",
    "print(\"x_t_beta : \", x_T_beta)\n",
    "print(\"w : \", w)\n",
    "#y=float(x.dot(beta))+0.1*np.random.rand(1)[0] ## y =x^T beta +w\n",
    "y=float(x_T_beta)+w ## y =x^T beta +w\n",
    "print(\"y : \", y)\n",
    "message=np.array2string(np.append([0,y],x),separator=\",\") \n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataFrame(data_file):\n",
    "    #Takes about one minute to load\n",
    "    data=pd.read_csv(data_conv,header=None,sep=\" \")\n",
    "    data.columns=[\"Date\",\"Hour\",\"Sensor\",\"Value\",\"Voltage\"]\n",
    "    data=data.sort_values(['Date','Hour']).reset_index(drop=True)\n",
    "    \n",
    "    data['datetime']=pd.to_datetime(data.Date+' '+data.Hour)\n",
    "    data['relative_datetime']=data['datetime']-data['datetime'][0]\n",
    "    data['seconds']=data['relative_datetime'].dt.total_seconds()\n",
    "    \n",
    "    sensorId_type=data.Sensor.str.split(\"-\",expand=True)\n",
    "    sensorId_type.columns=['SensorId','Type']\n",
    "    data['SensorId']=sensorId_type['SensorId'].astype(int)\n",
    "    data['Type']=sensorId_type['Type'].astype(int)\n",
    "    \n",
    "    #Drop features not needed for the simulation\n",
    "    data=data.drop(['datetime','relative_datetime','Sensor','Date','Hour','Voltage'],axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_conv = \"../data/data.conv.txt\"\n",
    "data = prepareDataFrame(data_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_1=data[(data.SensorId==1) & (data.Type==0) & (data.seconds<=8*86400)]\n",
    "temp_1=temp_1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_24=data[(data.SensorId==24) & (data.Type==0) & (data.seconds<=8*86400)]\n",
    "temp_24=temp_24.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 closest neighbors of sensor 1 are sensors 2, 3, 33, 34, 35\n",
    "neighbors_1 = [data[(data.SensorId==2) & (data.Type==0) & (data.seconds<=8*86400)],\\\n",
    "               data[(data.SensorId==3) & (data.Type==0) & (data.seconds<=8*86400)],\\\n",
    "               data[(data.SensorId==33) & (data.Type==0) & (data.seconds<=8*86400)],\\\n",
    "               data[(data.SensorId==34) & (data.Type==0) & (data.seconds<=8*86400)],\\\n",
    "               data[(data.SensorId==35) & (data.Type==0) & (data.seconds<=8*86400)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 closest neighbors of sensor 24 are sensors 22, 23, 25, 26, 27\n",
    "neighbors_24 = [data[(data.SensorId==22) & (data.Type==0) & (data.seconds<=8*86400)],\\\n",
    "                data[(data.SensorId==23) & (data.Type==0) & (data.seconds<=8*86400)],\\\n",
    "                data[(data.SensorId==25) & (data.Type==0) & (data.seconds<=8*86400)],\\\n",
    "                data[(data.SensorId==26) & (data.Type==0) & (data.seconds<=8*86400)],\\\n",
    "                data[(data.SensorId==27) & (data.Type==0) & (data.seconds<=8*86400)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTimeToSlots(dataframe):\n",
    "    interval_slot = 30\n",
    "    #divide data in slots of 30sec, add each slot value to each entry\n",
    "    dataframe[\"slot\"] = (dataframe[\"seconds\"]//interval_slot).astype(int)\n",
    "    #transform the seconds so that for each slot, its corresponding 'seconds' value is at the center of this slot (usefull for plots)\n",
    "    dataframe[\"seconds\"] = interval_slot*(dataframe[\"slot\"] + dataframe[\"slot\"]+1) / 2\n",
    "    \n",
    "    #Take care of the potential multiple value appearing within the same slot -> average them\n",
    "    dataframe = dataframe.groupby([\"slot\"]).agg(\"mean\")\n",
    "    dataframe.reset_index(level=0, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "def fillMissingRows(dataframe):\n",
    "    interval_slot = 30\n",
    "    missing_values = {\"slot\": [], \"seconds\": [], \"SensorId\": [], \"Type\": []}\n",
    "    for i in range (23040): #total nb of slots for 8 days\n",
    "        if i not in dataframe[\"slot\"].values:\n",
    "            seconds = interval_slot*(i + i+1) / 2\n",
    "            missing_values[\"slot\"].append(i)\n",
    "            missing_values[\"seconds\"].append(seconds)\n",
    "            missing_values[\"SensorId\"].append(1)\n",
    "            missing_values[\"Type\"].append(0)\n",
    "    #Build DataFrame with missing values\n",
    "    temp_missing = pd.DataFrame(missing_values)\n",
    "    #Merge the two Dataframe and sort them by values of the 'slot' column\n",
    "    #At this point, the temperature values are still missing -> NaN\n",
    "    complete_temp = dataframe.append(temp_missing).sort_values('slot')\n",
    "    #Replace NaN by values extracted from a linear method based on the neighbors\n",
    "    complete_temp[\"Value\"] = complete_temp[\"Value\"].interpolate(limit_direction=\"both\")    \n",
    "    return complete_temp\n",
    "\n",
    "def preprocessDataFrames(output_df, input_dfs):\n",
    "    output_df = fillMissingRows(convertTimeToSlots(output_df))\n",
    "    for i in range (len(input_dfs)):\n",
    "        input_dfs[i] = fillMissingRows(convertTimeToSlots(input_dfs[i]))\n",
    "    return output_df, input_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kais/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SensorId  Type      Value   seconds   slot\n",
      "0             1     0  19.243600      15.0      0\n",
      "1             1     0  19.243600      45.0      1\n",
      "0             1     0  19.243600      75.0      2\n",
      "2             1     0  19.237067     105.0      3\n",
      "3             1     0  19.230533     135.0      4\n",
      "1             1     0  19.224000     165.0      5\n",
      "2             1     0  19.214200     195.0      6\n",
      "4             1     0  19.199500     225.0      7\n",
      "3             1     0  19.184800     255.0      8\n",
      "5             1     0  19.189700     285.0      9\n",
      "4             1     0  19.194600     315.0     10\n",
      "6             1     0  19.184800     345.0     11\n",
      "5             1     0  19.175000     375.0     12\n",
      "6             1     0  19.184800     405.0     13\n",
      "7             1     0  19.184800     435.0     14\n",
      "7             1     0  19.184800     465.0     15\n",
      "8             1     0  19.175000     495.0     16\n",
      "8             1     0  19.168467     525.0     17\n",
      "9             1     0  19.161933     555.0     18\n",
      "9             1     0  19.155400     585.0     19\n",
      "10            1     0  19.155400     615.0     20\n",
      "10            1     0  19.148050     645.0     21\n",
      "11            1     0  19.140700     675.0     22\n",
      "12            1     0  19.133350     705.0     23\n",
      "11            1     0  19.126000     735.0     24\n",
      "12            1     0  19.145600     765.0     25\n",
      "13            1     0  19.126000     795.0     26\n",
      "13            1     0  19.129267     825.0     27\n",
      "14            1     0  19.132533     855.0     28\n",
      "14            1     0  19.135800     885.0     29\n",
      "...         ...   ...        ...       ...    ...\n",
      "14782         1     0  22.742200  690315.0  23010\n",
      "14783         1     0  22.752000  690345.0  23011\n",
      "14784         1     0  22.752000  690375.0  23012\n",
      "14785         1     0  22.752000  690405.0  23013\n",
      "14786         1     0  22.752000  690435.0  23014\n",
      "8228          1     0  22.748080  690465.0  23015\n",
      "8229          1     0  22.744160  690495.0  23016\n",
      "8230          1     0  22.740240  690525.0  23017\n",
      "8231          1     0  22.736320  690555.0  23018\n",
      "14787         1     0  22.732400  690585.0  23019\n",
      "14788         1     0  22.722600  690615.0  23020\n",
      "14789         1     0  22.722600  690645.0  23021\n",
      "8232          1     0  22.722600  690675.0  23022\n",
      "8233          1     0  22.722600  690705.0  23023\n",
      "14790         1     0  22.722600  690735.0  23024\n",
      "14791         1     0  22.712800  690765.0  23025\n",
      "14792         1     0  22.712800  690795.0  23026\n",
      "14793         1     0  22.693200  690825.0  23027\n",
      "14794         1     0  22.693200  690855.0  23028\n",
      "14795         1     0  22.693200  690885.0  23029\n",
      "14796         1     0  22.693200  690915.0  23030\n",
      "14797         1     0  22.673600  690945.0  23031\n",
      "14798         1     0  22.673600  690975.0  23032\n",
      "14799         1     0  22.673600  691005.0  23033\n",
      "14800         1     0  22.673600  691035.0  23034\n",
      "14801         1     0  22.683400  691065.0  23035\n",
      "8234          1     0  22.685850  691095.0  23036\n",
      "8235          1     0  22.688300  691125.0  23037\n",
      "8236          1     0  22.690750  691155.0  23038\n",
      "14802         1     0  22.693200  691185.0  23039\n",
      "\n",
      "[23040 rows x 5 columns]\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "temp_1, neighbors_1 = preprocessDataFrames(temp_1, neighbors_1)    \n",
    "\n",
    "print(temp_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyRLS(output_df, inputs_df):\n",
    "    nb_features = len(inputs_df)\n",
    "    betas = np.zeros(nb_features)\n",
    "    V = np.diag(np.zeros(n)+10)\n",
    "    forgetting_factor = 1.0\n",
    "    \n",
    "\n",
    "            beta=state[1]\n",
    "        beta.shape=(n,1)\n",
    "        V=state[2]\n",
    "        mu=state[3]\n",
    "        sse=state[4]  ## sum of squared errors\n",
    "        N=state[5]   ## number of treated samples\n",
    "        x.shape=(1,n)\n",
    "        err=y-x.dot(beta)\n",
    "        sse=sse+pow(err,2.0)\n",
    "        V=1.0/mu*(V-V.dot(x.T).dot(x).dot(V)/(1.0+float(x.dot(V).dot(x.T))))\n",
    "        gamma=V.dot(x.T)\n",
    "        beta=beta+gamma*err\n",
    "        \n",
    "        return (key,beta,V,mu,sse/(N+1.0),N+1)  ## update formula mod1\n",
    "    \n",
    "#def mergeByslots(temp_data):\n",
    "#def mapSecondsToSlots(temperature_data, neighbors_data):\n",
    "#    interval_slot = 30  #30s slots\n",
    "#    nb_slots = int(86400/interval_slot)\n",
    "#    print(nb_slots)\n",
    "#    for day in range (0,8):\n",
    "        \n",
    "\n",
    "#def predictSlots(temperature_data, neighbors_data):\n",
    "#    interval_slot = 30  #30s slots\n",
    "#    nb_slots = int(86400/interval_slot)\n",
    "#    print(nb_slots)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b\n",
      "0  1  5\n",
      "1  2  6\n",
      "2  3  7\n",
      "3  4  8\n",
      "   a  b  c\n",
      "0  1  5  1\n",
      "1  2  6  5\n",
      "2  3  7  4\n",
      "   a  b    c\n",
      "0  1  5  NaN\n",
      "1  2  6  NaN\n",
      "2  3  7  NaN\n",
      "3  4  8  NaN\n",
      "4  1  5  1.0\n",
      "5  2  6  5.0\n",
      "6  3  7  4.0\n"
     ]
    }
   ],
   "source": [
    "# Creating the first Dataframe using dictionary \n",
    "df1 = pd.DataFrame({\"a\":[1, 2, 3, 4], \n",
    "                    \"b\":[5, 6, 7, 8]}) \n",
    "print(df1)\n",
    "# Creating the Second Dataframe using dictionary \n",
    "df2 = pd.DataFrame({\"a\":[1, 2, 3], \n",
    "                    \"b\":[5, 6, 7],  \n",
    "                    \"c\":[1, 5, 4]}) \n",
    "print(df2)\n",
    "  \n",
    "# for appending df2 at the end of df1 \n",
    "df = df1.append(df2, ignore_index = True) \n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
