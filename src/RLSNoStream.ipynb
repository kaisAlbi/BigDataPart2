{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "-----\n",
      "x:  [0.5850245  0.57933072 0.67363201 0.80047994 0.25907805 0.9099468\n",
      " 0.09312666 0.81951488 0.49311056 0.37880294]\n",
      "x_t_beta :  [0.95813366]\n",
      "w :  0.010612732834882455\n",
      "y :  0.9687463959230191\n",
      "[0.        ,0.9687464 ,0.5850245 ,0.57933072,0.67363201,0.80047994,\n",
      " 0.25907805,0.9099468 ,0.09312666,0.81951488,0.49311056,0.37880294]\n"
     ]
    }
   ],
   "source": [
    "n=10   # number of inputs\n",
    "\n",
    "beta=np.zeros(n) ## first and last parameters are 1, others are zeros\n",
    "beta[1]=1   \n",
    "beta[-1]=1\n",
    "print(beta)\n",
    "beta.shape=(n,1)\n",
    "print(beta)\n",
    "print(\"-----\")\n",
    "x=np.random.rand(1,n)[0]\n",
    "print(\"x: \", x)\n",
    "x_T_beta = x.dot(beta)\n",
    "w = 0.1*np.random.rand(1)[0]\n",
    "print(\"x_t_beta : \", x_T_beta)\n",
    "print(\"w : \", w)\n",
    "#y=float(x.dot(beta))+0.1*np.random.rand(1)[0] ## y =x^T beta +w\n",
    "y=float(x_T_beta)+w ## y =x^T beta +w\n",
    "print(\"y : \", y)\n",
    "message=np.array2string(np.append([0,y],x),separator=\",\") \n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataFrame(data_file):\n",
    "    #Takes about one minute to load\n",
    "    data=pd.read_csv(data_conv,header=None,sep=\" \")\n",
    "    data.columns=[\"Date\",\"Hour\",\"Sensor\",\"Value\",\"Voltage\"]\n",
    "    data=data.sort_values(['Date','Hour']).reset_index(drop=True)\n",
    "    \n",
    "    data['datetime']=pd.to_datetime(data.Date+' '+data.Hour)\n",
    "    data['relative_datetime']=data['datetime']-data['datetime'][0]\n",
    "    data['seconds']=data['relative_datetime'].dt.total_seconds()\n",
    "    \n",
    "    sensorId_type=data.Sensor.str.split(\"-\",expand=True)\n",
    "    sensorId_type.columns=['SensorId','Type']\n",
    "    data['SensorId']=sensorId_type['SensorId'].astype(int)\n",
    "    data['Type']=sensorId_type['Type'].astype(int)\n",
    "    \n",
    "    #Drop features not needed for the simulation\n",
    "    data=data.drop(['datetime','relative_datetime','Sensor','Date','Hour','Voltage'],axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_conv = \"../data/data.conv.txt\"\n",
    "data = prepareDataFrame(data_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_1=data[(data.SensorId==1) & (data.Type==0) & (data.seconds<=8*86400)]\n",
    "temp_1=temp_1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_24=data[(data.SensorId==24) & (data.Type==0) & (data.seconds<=8*86400)]\n",
    "temp_24=temp_24.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 closest neighbors of sensor 1 are sensors 2, 3, 33, 34, 35\n",
    "neighbors_1 = [data[(data.SensorId==2) & (data.Type==0) & (data.seconds<=8*86400)],\\\n",
    "               data[(data.SensorId==3) & (data.Type==0) & (data.seconds<=8*86400)],\\\n",
    "               data[(data.SensorId==33) & (data.Type==0) & (data.seconds<=8*86400)],\\\n",
    "               data[(data.SensorId==34) & (data.Type==0) & (data.seconds<=8*86400)],\\\n",
    "               data[(data.SensorId==35) & (data.Type==0) & (data.seconds<=8*86400)]]\n",
    "\n",
    "for neighbor in neighbors_1:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 closest neighbors of sensor 24 are sensors 22, 23, 25, 26, 27\n",
    "neighbors_24 = [data[(data.SensorId==22) & (data.Type==0) & (data.seconds<=8*86400)],\\\n",
    "                data[(data.SensorId==23) & (data.Type==0) & (data.seconds<=8*86400)],\\\n",
    "                data[(data.SensorId==25) & (data.Type==0) & (data.seconds<=8*86400)],\\\n",
    "                data[(data.SensorId==26) & (data.Type==0) & (data.seconds<=8*86400)],\\\n",
    "                data[(data.SensorId==27) & (data.Type==0) & (data.seconds<=8*86400)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTimeToSlots(dataframe):\n",
    "    interval_slot = 30\n",
    "    #divide data in slots of 30sec, add each slot value to each entry\n",
    "    dataframe[\"slot\"] = (dataframe[\"seconds\"]//interval_slot).astype(int)\n",
    "    #transform the seconds so that for each slot, its corresponding 'seconds' value is at the center of this slot (usefull for plots)\n",
    "    dataframe[\"seconds\"] = interval_slot*(dataframe[\"slot\"] + dataframe[\"slot\"]+1) / 2\n",
    "    \n",
    "    #Take care of the potential multiple value appearing within the same slot -> average them\n",
    "    dataframe = dataframe.groupby([\"slot\"]).agg(\"mean\")\n",
    "    dataframe.reset_index(level=0, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "def fillMissingRows(dataframe):\n",
    "    interval_slot = 30\n",
    "    nb_slots = 23040\n",
    "    missing_values = {\"slot\": [], \"seconds\": [], \"SensorId\": [], \"Type\": []}\n",
    "    for i in range (nb_slots): #total nb of slots for 8 days\n",
    "        if i not in dataframe[\"slot\"].values:\n",
    "            seconds = interval_slot*(i + i+1) / 2\n",
    "            missing_values[\"slot\"].append(i)\n",
    "            missing_values[\"seconds\"].append(seconds)\n",
    "            missing_values[\"SensorId\"].append(1)\n",
    "            missing_values[\"Type\"].append(0)\n",
    "    #Build DataFrame with missing values\n",
    "    temp_missing = pd.DataFrame(missing_values)\n",
    "    #Merge the two Dataframe and sort them by values of the 'slot' column\n",
    "    #At this point, the temperature values are still missing -> NaN\n",
    "    complete_temp = dataframe.append(temp_missing).sort_values('slot')\n",
    "    #Replace NaN by values extracted from a linear method based on the neighbors\n",
    "    complete_temp[\"Value\"] = complete_temp[\"Value\"].interpolate(limit_direction=\"both\")    \n",
    "    return complete_temp\n",
    "\n",
    "def preprocessDataFrames(output_df, input_dfs):\n",
    "    output_df = fillMissingRows(convertTimeToSlots(output_df))\n",
    "    for i in range (len(input_dfs)):\n",
    "        input_dfs[i] = fillMissingRows(convertTimeToSlots(input_dfs[i]))\n",
    "    merged_inputs_dfs = pd.concat(input_dfs) \n",
    "    return output_df, merged_inputs_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kais/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "temp_1, merged_neighbors_1 = preprocessDataFrames(temp_1, neighbors_1)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SensorId  Type    Value  seconds  slot\n",
      "0       1.0   0.0  19.2436     15.0   0.0\n",
      "   SensorId  Type    Value  seconds  slot\n",
      "0       2.0   0.0  19.6160     15.0   0.0\n",
      "0       3.0   0.0  19.5278     15.0   0.0\n",
      "0      33.0   0.0  19.1456     15.0   0.0\n",
      "0       1.0   0.0  18.4988     15.0   0.0\n",
      "0      35.0   0.0  19.4200     15.0   0.0\n"
     ]
    }
   ],
   "source": [
    "output = temp_1[temp_1.slot == 0]\n",
    "print(output)\n",
    "input_df= merged_neighbors_1[merged_neighbors_1.slot == 0]\n",
    "print(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyRLS(output_df, inputs_dfs):\n",
    "    nb_slots = 23040\n",
    "    nb_features = len(inputs_dfs)\n",
    "    betas = np.zeros(nb_features)\n",
    "    covar_matrix = np.diag(np.zeros(n)+1)\n",
    "    forgetting_factor = 1.0\n",
    "    predictions = []\n",
    "    for slot in range (nb_slots):\n",
    "        output = output_df[output_df.slot == slot].Value\n",
    "        inputs = [input_df[input_df.slot == slot].Value for input_df in inputs_dfs]\n",
    "\n",
    "            beta=state[1]\n",
    "        beta.shape=(n,1)\n",
    "        V=state[2]\n",
    "        mu=state[3]\n",
    "        sse=state[4]  ## sum of squared errors\n",
    "        N=state[5]   ## number of treated samples\n",
    "        x.shape=(1,n)\n",
    "        err=y-x.dot(beta)\n",
    "        sse=sse+pow(err,2.0)\n",
    "        V=1.0/mu*(V-V.dot(x.T).dot(x).dot(V)/(1.0+float(x.dot(V).dot(x.T))))\n",
    "        gamma=V.dot(x.T)\n",
    "        beta=beta+gamma*err\n",
    "        \n",
    "        return (key,beta,V,mu,sse/(N+1.0),N+1)  ## update formula mod1\n",
    "    \n",
    "#def mergeByslots(temp_data):\n",
    "#def mapSecondsToSlots(temperature_data, neighbors_data):\n",
    "#    interval_slot = 30  #30s slots\n",
    "#    nb_slots = int(86400/interval_slot)\n",
    "#    print(nb_slots)\n",
    "#    for day in range (0,8):\n",
    "        \n",
    "\n",
    "#def predictSlots(temperature_data, neighbors_data):\n",
    "#    interval_slot = 30  #30s slots\n",
    "#    nb_slots = int(86400/interval_slot)\n",
    "#    print(nb_slots)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 10.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. 10.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. 10.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. 10.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0. 10.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. 10.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0. 10.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0. 10.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0. 10.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.diag(np.zeros(n)+10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
